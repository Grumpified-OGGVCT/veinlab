# ğŸ”® VeinLab - Ollama Cloud Capability Explorer

**Tagline:** *"From curiosity to code in 60 seconds"*

[![GitHub Pages](https://img.shields.io/badge/demo-live-success)](https://grumpified-oggvct.github.io/veinlab/)
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)

An interactive GitHub Pages app that lets developers **discover**, **experiment**, and **ship** with Ollama Cloud models.

## ğŸ¯ What It Does

VeinLab provides 6 comprehensive interactive demos showcasing Ollama Cloud capabilities:

### 1. ğŸ’¬ Multi-Model Chat Arena
- Compare responses from `gpt-oss:120b-cloud`, `deepseek-v3.1:671b-cloud`, `kimi-k2:1t-cloud`
- Side-by-side streaming responses
- **Uses:** Cloud API, Streaming, Multiple models

### 2. ğŸ‘ï¸ Vision Analyzer
- Upload images via drag & drop
- 4 pre-built analysis templates (Describe, Objects, OCR, Style)
- **Uses:** `qwen3-vl:235b-cloud`, Vision capability, Structured Outputs

### 3. ğŸ” Web-Augmented Q&A
- Ask questions, AI searches web for current info
- Shows sources + AI synthesis
- **Uses:** Web search capability, Tool calling

### 4. ï¿½ï¿½ Code Assistant
- 6 tasks: Generate, Explain, Debug, Optimize, Convert, Document
- Supports 10+ languages (Python, JavaScript, TypeScript, Java, C++, Go, Rust, etc.)
- **Uses:** `qwen3-coder:480b-cloud`, Structured Outputs

### 5. ğŸ› ï¸ Function Caller Playground
- 6 pre-built tools (weather, calculator, search, email, datetime, currency)
- Watch AI decide when to use them
- **Uses:** Tool calling, Function definitions

### 6. ğŸŒ Ecosystem Dashboard
- Live data from Ollama Pulse reports
- 127 models across 5 categories
- Trending cloud models showcase
- **Uses:** Data visualization, Model discovery

## ğŸš€ Quick Start

### View Live Demo
Visit **[https://grumpified-oggvct.github.io/veinlab/](https://grumpified-oggvct.github.io/veinlab/)**

### Run Locally
```bash
git clone https://github.com/Grumpified-OGGVCT/veinlab.git
cd veinlab/docs
# Open index.html in your browser
# Or use a local server:
python -m http.server 8000
# Visit http://localhost:8000
```

### Use the API Client
```javascript
import { OllamaClient } from './assets/js/ollama-client.js';

const client = new OllamaClient('your-api-key');

// Chat with streaming
const stream = await client.chat('deepseek-v3.1:671b-cloud', [
  { role: 'user', content: 'Explain quantum computing' }
], { stream: true });

for await (const chunk of stream) {
  process.stdout.write(chunk);
}

// Vision analysis
const result = await client.vision(
  'qwen3-vl:235b-cloud',
  'Describe this image',
  imageBase64
);
```

## ğŸ“ Project Structure

```
veinlab/
â”œâ”€â”€ docs/                       # GitHub Pages root
â”‚   â”œâ”€â”€ index.html             # Landing page
â”‚   â”œâ”€â”€ playground/            # Interactive demos
â”‚   â”‚   â”œâ”€â”€ chat-arena.html
â”‚   â”‚   â”œâ”€â”€ vision.html
â”‚   â”‚   â”œâ”€â”€ search.html
â”‚   â”‚   â”œâ”€â”€ code.html
â”‚   â”‚   â”œâ”€â”€ tools.html
â”‚   â”‚   â””â”€â”€ ecosystem.html
â”‚   â”œâ”€â”€ assets/
â”‚   â”‚   â”œâ”€â”€ js/
â”‚   â”‚   â”‚   â””â”€â”€ ollama-client.js  # Reusable API wrapper
â”‚   â”‚   â””â”€â”€ css/
â”‚   â”‚       â””â”€â”€ main.css          # Dark theme styling
â”‚   â””â”€â”€ data/                  # Pulse reports (future)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

## ğŸ› ï¸ Tech Stack

- **Zero Dependencies** - Pure vanilla JavaScript
- **100% Client-Side** - No backend required
- **GitHub Pages** - Free hosting
- **Ollama Cloud API** - Cloud-scale LLM inference
- **Responsive Design** - Mobile-first CSS (375px - 1920px)

## ğŸŒŸ Features

âœ… **See Before You Code** - Test capabilities interactively  
âœ… **Copy Working Examples** - Production-ready code snippets  
âœ… **Compare Models** - Side-by-side model comparison  
âœ… **Discover Ecosystem** - Trending models and projects  
âœ… **Zero Setup** - Runs entirely in browser  
âœ… **Open Source** - MIT licensed, fork and customize  

## ğŸ”‘ API Key Setup

1. Get your Ollama Cloud API key from [ollama.com](https://ollama.com)
2. Each demo has an API key input field
3. Keys are stored in browser localStorage (never sent to servers)
4. For production use, implement proper key management

## ğŸ“Š Supported Models

### Cloud Models (7 total)
- `deepseek-v3.1:671b-cloud` - Massive reasoning (671B params)
- `kimi-k2:1t-cloud` - 1 trillion parameter powerhouse
- `qwen3-coder:480b-cloud` - Specialized coding model
- `gpt-oss:120b-cloud` - Open source GPT alternative
- `qwen3-vl:235b-cloud` - Vision-language model
- `glm-4.6:cloud` - Advanced reasoning with 200K context
- `gpt-oss:20b-cloud` - Efficient general model

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

MIT License - see [LICENSE](LICENSE) file for details

## ğŸ™ Acknowledgments

- Built with [Ollama Cloud](https://ollama.com)
- Inspired by the Ollama community
- Daily ecosystem data from [Ollama Pulse](https://github.com/Grumpified-OGGVCT/ollama_pulse)

## ğŸ“§ Contact

- GitHub: [@Grumpified-OGGVCT](https://github.com/Grumpified-OGGVCT)
- Project: [VeinLab](https://github.com/Grumpified-OGGVCT/veinlab)

---

**âš¡ VeinLab** - Where Ollama Cloud Capabilities Come Alive
